

# MLPRegressor
Regression with a multi-layer perceptron







[Using FluCoMa to Make a Shared Instrument ](/explore/eldridge-kiefer)[Exploring the Oboe with FluCoMa ](/explore/harker)[Levels of Translation ](/explore/moore)[Interface Design with FluCoMa ](/explore/pluta)[Fleeting Networks ](/explore/tremblay)[Neural Network Parameters ](/learn/mlp-parameters)[Neural Network Training ](/learn/mlp-training)[Training and Testing Data ](/learn/training-testing-split)[Controlling a Synth using a Neural Network ](/learn/regression-neural-network)[DataSet ](/reference/dataset)The MLPRegressor is a neural network that can be used to perform regression. In machine learning, regression can be thought of as a mapping from one space to another where each space can be any number of dimensions. “MLP” stands for multi-layer perceptron which is a type of neural network.PointerFor more information on using this object, visit[MLP Training](/learn/mlp-training),[MLP Parameters](/learn/mlp-parameters), and[Training-Testing Split](/learn/training-testing-split).By providing input and output data as[DataSets](/reference/dataset), the neural network is trained using*supervised learning*to predict output data points based on input data points. See this[YouTube tutorial](/learn/regression-neural-network)that uses the MLPRegressor to control a synthesiser with 10 control parameters (as the output) using only 2 control parameters of an XY pad (as the input).